{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e678634",
   "metadata": {},
   "source": [
    "# Day 1: PyTorch 数据加载基础（Dataset 与 DataLoader）\n",
    "\n",
    "在深度学习项目中，数据的加载与预处理是整个流程的基础。本节重点介绍 PyTorch 提供的两个核心工具：\n",
    "- **`torch.utils.data.Dataset`**：自定义数据集的抽象基类\n",
    "- **`torch.utils.data.DataLoader`**：用于批量加载数据、支持多进程、自动 shuffle 等\n",
    "\n",
    "通过这两个工具，我们可以快速构建高效、灵活的数据管道。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1daa4af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3812f0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Adult dataset to ../data/Adult/X.csv...\n",
      "Download finished.\n",
      "Download finished.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "save_dir = '../data/Adult'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "file_path = os.path.join(save_dir, 'X.csv')\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    "if not os.path.exists(file_path):\n",
    "    print(f\"Downloading Adult dataset to {file_path}...\")\n",
    "    r = requests.get(url)\n",
    "    with open(file_path, 'wb') as f:\n",
    "        f.write(r.content)\n",
    "    print(\"Download finished.\")\n",
    "else:\n",
    "    print(\"Dataset already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca34d750",
   "metadata": {},
   "source": [
    "## 自定义 Dataset 类：三个必需方法\n",
    "\n",
    "自定义数据集类需要继承 `torch.utils.data.Dataset`，并重写以下**三个核心方法**：\n",
    "\n",
    "1. **`__init__(self, ...)`**：初始化数据集\n",
    "   - 加载数据文件（CSV、图像目录等）\n",
    "   - 存储数据路径、标签、转换操作等\n",
    "   \n",
    "2. **`__len__(self)`**：返回数据集大小\n",
    "   - 用于 DataLoader 计算 epoch 中的 batch 数量\n",
    "   \n",
    "3. **`__getitem__(self, idx)`**：根据索引返回数据项\n",
    "   - 返回单个样本（通常是 (feature, label) 元组）\n",
    "   - 在这里应用数据增强（augmentation）或转换\n",
    "\n",
    "**设计原则**：Dataset 只负责返回单个样本，DataLoader 负责批量化与并行加载。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da17b8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    \"\"\"\n",
    "    自定义 Dataset 示例：从 CSV 文件加载数据\n",
    "    \n",
    "    Args:\n",
    "        filepath (str): CSV 文件路径\n",
    "        transform (callable, optional): 应用于样本的转换函数\n",
    "    \"\"\"\n",
    "    def __init__(self, filepath='../data/Adult/X.csv', transform=None): \n",
    "        \"\"\"加载数据并初始化\"\"\"\n",
    "        self.data = pd.read_csv(filepath, header=None, na_values=' ?').select_dtypes(include=['number'])\n",
    "        self.data = self.data.fillna(0)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"返回数据集大小\"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        根据索引返回单个样本\n",
    "        \n",
    "        Args:\n",
    "            idx (int): 样本索引\n",
    "            \n",
    "        Returns:\n",
    "            样本（原始或转换后）\n",
    "        \"\"\"\n",
    "        sample = self.data.iloc[idx]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30b3db41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor:\n",
    "    \"\"\"\n",
    "    将 pandas Series（一行数据）转换为 PyTorch tensor\n",
    "    \n",
    "    这个转换类可以在 Dataset 的 __getitem__ 中调用，用于数据预处理。\n",
    "    \"\"\"\n",
    "    def __call__(self, sample):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            sample (pd.Series): 单行数据\n",
    "            \n",
    "        Returns:\n",
    "            torch.Tensor: float32 类型的张量\n",
    "        \"\"\"\n",
    "        return torch.tensor(sample.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e3bdba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集大小: 32561\n",
      "DataLoader batch 数: 1018\n"
     ]
    }
   ],
   "source": [
    "# 创建 Dataset 实例并用 DataLoader 包装\n",
    "data = MyDataset(transform=ToTensor())\n",
    "dataloader = DataLoader(\n",
    "    data, \n",
    "    batch_size=32, \n",
    "    shuffle=True,\n",
    "    num_workers=0  # CPU 为 0，若要多进程则设置 > 0\n",
    ")\n",
    "\n",
    "print(f\"数据集大小: {len(data)}\")\n",
    "print(f\"DataLoader batch 数: {len(dataloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000c8846",
   "metadata": {},
   "source": [
    "## 数据预处理与缺失值处理\n",
    "\n",
    "**重要提示**：上面的 `MyDataset` 只读取了数值数据。实际项目中，**通常需要先做数据预处理**：\n",
    "\n",
    "1. **处理缺失值**（pandas + sklearn）\n",
    "2. **特征编码**（独热编码、标准化等）\n",
    "3. **数据验证**（检查异常值、数据类型等）\n",
    "\n",
    "**推荐流程**：\n",
    "\n",
    "原始 CSV → pandas 清洗/预处理 → 保存为中间文件或缓存 → Dataset 读取 → Tensor 转换 → DataLoader 批量化\n",
    "\n",
    "\n",
    "这样做的好处是预处理步骤只需运行一次，之后可以快速加载。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dd71b6",
   "metadata": {},
   "source": [
    "## 实践示例：迭代 DataLoader 并观察批量数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54956177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一个批次数据形状: torch.Size([32, 6])\n"
     ]
    }
   ],
   "source": [
    "batch_data = next(iter(dataloader))\n",
    "print(f\"一个批次数据形状: {batch_data.shape}\") # 应为 [batch_size, num_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f0bc64",
   "metadata": {},
   "source": [
    "## DataLoader 的关键参数\n",
    "\n",
    "| 参数 | 说明 | 默认值 | 备注 |\n",
    "|------|------|--------|------|\n",
    "| `batch_size` | 每批样本数 | 1 | 通常设为 32/64/128 |\n",
    "| `shuffle` | 是否打乱数据 | False | 训练时应设为 True；验证/测试时设为 False |\n",
    "| `num_workers` | 多进程数 | 0 | 0 表示单进程；>0 时可加速数据加载 |\n",
    "| `pin_memory` | 是否锁定内存 | False | GPU 训练时可设为 True，加快数据传输 |\n",
    "| `drop_last` | 是否丢弃最后不足一批的样本 | False | 某些情况（如 BatchNorm）下应设为 True |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19feddba",
   "metadata": {},
   "source": [
    "## 常见问题与最佳实践\n",
    "\n",
    "**Q1：什么时候使用 `num_workers > 0`？**\n",
    "- 数据集很大（> 10K 样本）且 Dataset 加载较慢时，多进程可显著加速。\n",
    "- 在 CPU 上开发时通常设为 0，避免多进程调试困难。\n",
    "\n",
    "**Q2：为什么 DataLoader 迭代后内存没有释放？**\n",
    "- 检查是否保持了对 batch 数据的引用。设为 `None` 显式释放或使用 `del`。\n",
    "\n",
    "**Q3：如何在 Dataset 中实现数据增强（augmentation）？**\n",
    "- 在 `__getitem__` 中应用转换：`if self.train: sample = apply_augmentation(sample)`\n",
    "\n",
    "**Q4：Dataset 中可以返回多个输出吗（如 (feature, label, metadata)）？**\n",
    "- 完全可以。DataLoader 会自动按位置堆叠，返回 `(batch_features, batch_labels, batch_metadata)`。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e38b34",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "Dataset 与 DataLoader 是 PyTorch 数据管道的核心：\n",
    "- **Dataset**：定义数据加载与预处理逻辑（样本级别）\n",
    "- **DataLoader**：自动进行批量化、打乱、多进程加载（批级别）\n",
    "\n",
    "正确设计数据加载流程能显著提升训练效率与代码可维护性。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
